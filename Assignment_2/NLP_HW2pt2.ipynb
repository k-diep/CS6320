{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E814tOBjxtGK"
   },
   "source": [
    "## Used Google Colab, need this extra step to mount the drive. Other Jupyter notebooks can skip this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-qqGrvG1Iim",
    "outputId": "c309a4df-277a-4ddb-f501-49112a95c58c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "90HW5qAC1YdL"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RymHhtCXkwlx",
    "outputId": "72f44e5e-3a38-40ef-9b2b-e0532b2a9e97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVQMfmHSx26d"
   },
   "source": [
    "## Path of where the pickle data (from part 1) is stored on Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "HySUSVxw2p7P"
   },
   "outputs": [],
   "source": [
    "pickle_path = '/content/drive/MyDrive/NLP_Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "att2O5a48fZD"
   },
   "source": [
    "## Read in the pickled dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "O_nByGLe1UuT"
   },
   "outputs": [],
   "source": [
    "with open(pickle_path + 'english_unigram.pickle', 'rb') as handle:\n",
    "  english_unigram = pickle.load(handle)\n",
    "\n",
    "with open(pickle_path + 'english_bigram.pickle', 'rb') as handle:\n",
    "  english_bigram = pickle.load(handle)\n",
    "\n",
    "with open(pickle_path + 'french_unigram.pickle', 'rb') as handle:\n",
    "  french_unigram = pickle.load(handle)\n",
    "\n",
    "with open(pickle_path + 'french_bigram.pickle', 'rb') as handle:\n",
    "  french_bigram = pickle.load(handle)\n",
    "\n",
    "with open(pickle_path + 'italian_unigram.pickle', 'rb') as handle:\n",
    "  italian_unigram = pickle.load(handle)\n",
    "\n",
    "with open(pickle_path + 'italian_bigram.pickle', 'rb') as handle:\n",
    "  italian_bigram = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtXU82nbYiru"
   },
   "source": [
    "## Calculate the probability of the simplified Laplace smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "bqcbl_xAUjgg"
   },
   "outputs": [],
   "source": [
    "# Adapted code from https://github.com/kjmazidi/NLP/blob/master/Part_2-Words/Chapter_08_ngrams/8_ngrams_1.ipynb\n",
    "# Only care about the p_laplace part of this link\n",
    "\n",
    "import math\n",
    "def compute_prob(text, unigram_dict, bigram_dict, V):\n",
    "  # V is the vocabulary size in the training data (unique tokens)\n",
    "\n",
    "  unigrams_text = word_tokenize(text)\n",
    "  bigrams_text = list(ngrams(unigrams_text, 2))\n",
    "\n",
    "  p_laplace = 1\n",
    "  # UNCOMMENT for p_log method\n",
    "  p_log = 0\n",
    "\n",
    "  # (b + 1) / (u + v)\n",
    "  # where b is the bigram count, u is the unigram count of the first word in the bigram, and v is the total\n",
    "  # vocabulary size (add the lengths of the 3 unigram dictionaries)\n",
    "  for bigram in bigrams_text:\n",
    "    b = bigram_dict[bigram] if bigram in bigram_dict else 0\n",
    "    u = unigram_dict[bigram[0]] if bigram[0] in unigram_dict else 0\n",
    "    p_laplace = p_laplace * ((b + 1) / (u + V))\n",
    "    # UNCOMMENT for p_log method\n",
    "    # p_log = p_log + math.log((b + 1) / (u + V))\n",
    "\n",
    "  # UNCOMMENT for p_log method\n",
    "  #return p_log\n",
    "  return p_laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "F4oIwzfRnG3g"
   },
   "outputs": [],
   "source": [
    "# Given the Probability of each language, return the highest\n",
    "def find_largest_prob(english_prob, french_prob, italian_prob):\n",
    "    predicted_language = \"\"\n",
    "    if english_prob == max(english_prob, french_prob, italian_prob):\n",
    "      predicted_language = \"English\"\n",
    "    elif french_prob == max(english_prob, french_prob, italian_prob):\n",
    "      predicted_language = \"French\"\n",
    "    elif italian_prob == max(english_prob, french_prob, italian_prob):\n",
    "      predicted_language = \"Italian\"\n",
    "\n",
    "    return predicted_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9ap5tLfjWMf",
    "outputId": "390e72e0-003d-408c-8d09-41d9c0d069fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24842\n",
      "English Probability: 1.362160002573524e-24\n",
      "French Probability: 1.677330508845522e-33\n",
      "Italian Probability: 5.713973624389234e-36\n",
      "Predicted Language: English\n"
     ]
    }
   ],
   "source": [
    "# Testing the previous two functions\n",
    "# raw_text = \"À mon avis , cette deuxième hypothèse signifierait le rejet de nos responsabilités en tant que Parlement , outre l ' introduction d ' une thèse originale , d ' une méthode inconnue qui consiste à communiquer aux groupes politiques le discours du programme de la Commission par écrit une semaine avant ­ - et non le jour avant , comme il avait été convenu - ­ , en tenant compte du fait que le programme législatif serait discuté en février , de telle sorte que nous pourrions nous passer du débat , car le lendemain , la presse et Internet l ' auraient porté à la connaissance de tous les citoyens et le Parlement n ' aurait plus de raison de s ' en occuper .\"\n",
    "raw_text = \"Madam President , on a point of order .\"\n",
    "V = len(english_unigram) + len(french_unigram) + len(italian_unigram)\n",
    "print(V)\n",
    "\n",
    "english_prob = compute_prob(raw_text, english_unigram, english_bigram, V)\n",
    "french_prob  = compute_prob(raw_text, french_unigram, french_bigram, V)\n",
    "italian_prob = compute_prob(raw_text, italian_unigram, italian_bigram, V)\n",
    "print(\"English Probability:\", english_prob)\n",
    "print(\"French Probability:\", french_prob)\n",
    "print(\"Italian Probability:\", italian_prob)\n",
    "\n",
    "predicted_language = find_largest_prob(english_prob, french_prob, italian_prob)\n",
    "print(\"Predicted Language:\", predicted_language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEWRNre0zElL"
   },
   "source": [
    "## Process each line from 'LangId.test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "tXRRvFwhviMd"
   },
   "outputs": [],
   "source": [
    "# Where the data is stored on Google Drive\n",
    "folder_path = '/content/drive/MyDrive/NLP_Data/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "CuFk4WlDgEHf"
   },
   "outputs": [],
   "source": [
    "file_name = 'LangId.test.txt'\n",
    "file_path = folder_path + file_name\n",
    "lines = []\n",
    "# Attempt to open the file\n",
    "try:\n",
    "  with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "      # Could process the Probabilities here instead of appending. But for readability reasons processed it later\n",
    "\n",
    "      # Append each line to lines\n",
    "      lines.append(line.strip())  # Use strip() to remove leading/trailing whitespaces\n",
    "\n",
    "# Catch if file could not be found\n",
    "except FileNotFoundError:\n",
    "  print(\"The file, \", file_name, \", cannot be found\")\n",
    "  sys.exit(1)\n",
    "\n",
    "# Catch all other errors\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJ_n1HVyyh2N"
   },
   "source": [
    "## Calculating the probability for each line of 'LangId.test.txt' and write the language with the highest probability to a text file (\"predicted_language.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "ipWnQGzrwDzA"
   },
   "outputs": [],
   "source": [
    "write_file_path = folder_path + \"predicted_language.txt\"\n",
    "\n",
    "# Erase all contents of \"predicted_language.txt\"\n",
    "lang_file = open(write_file_path, 'w')\n",
    "lang_file.write(\"\")\n",
    "lang_file.close()\n",
    "\n",
    "# Processing each line in \"predicted_language.txt\"\n",
    "for line in lines:\n",
    "  # Calculating each probability\n",
    "  english_prob = compute_prob(line, english_unigram, english_bigram, V)\n",
    "  french_prob  = compute_prob(line, french_unigram, french_bigram, V)\n",
    "  italian_prob = compute_prob(line, italian_unigram, italian_bigram, V)\n",
    "\n",
    "  # Predicting the language of the line\n",
    "  predicted_language = find_largest_prob(english_prob, french_prob, italian_prob)\n",
    "  # print(\"Predicted Language:\", predicted_language)\n",
    "\n",
    "  # Write the predicted language to \"predicted_language.txt\"\n",
    "  lang_file = open(write_file_path, 'a')\n",
    "  lang_file.write(predicted_language + '\\n')\n",
    "  lang_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pmg6-0ybzPGP"
   },
   "source": [
    "## Compute and output your accuracy as the percentage of correctly classified instances in the test set. The file LangId.sol holds the correct classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N2tDPc_TOkUZ",
    "outputId": "5cde966f-8dc0-404c-a6f0-95dead1dc969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong predicted language at line 24\n",
      "Predicted language: English\n",
      "Actual language: French\n",
      "\n",
      "Wrong predicted language at line 44\n",
      "Predicted language: French\n",
      "Actual language: Italian\n",
      "\n",
      "Wrong predicted language at line 92\n",
      "Predicted language: French\n",
      "Actual language: English\n",
      "\n",
      "Wrong predicted language at line 187\n",
      "Predicted language: English\n",
      "Actual language: Italian\n",
      "\n",
      "Wrong predicted language at line 191\n",
      "Predicted language: English\n",
      "Actual language: French\n",
      "\n",
      "Wrong predicted language at line 247\n",
      "Predicted language: English\n",
      "Actual language: Italian\n",
      "\n",
      "Wrong predicted language at line 277\n",
      "Predicted language: English\n",
      "Actual language: Italian\n",
      "\n",
      "Wrong predicted language at line 279\n",
      "Predicted language: English\n",
      "Actual language: French\n",
      "\n",
      "Number of languages predicted right: 292\n",
      "Number of languages predicted wrong: 8\n",
      "Accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "test_path = folder_path + \"LangId.sol.txt\"\n",
    "predicted_right = 0\n",
    "predicted_wrong = 0\n",
    "\n",
    "with open(write_file_path, 'r') as predicted_language, open(test_path, 'r') as test_file:\n",
    "  for predict_line, test_line in zip(predicted_language, test_file):\n",
    "    # Gets rid of new lines with strip()\n",
    "    predicted = predict_line.strip()\n",
    "    actual = test_line.strip()\n",
    "\n",
    "    # From the \"LangId.sol.txt\", split the line and get the second string from split\n",
    "    line_number = actual.split()[0]\n",
    "    actual = actual.split()[1]\n",
    "\n",
    "    # print(predicted)\n",
    "    # print(actual)\n",
    "    # print(\"---------------------\")\n",
    "\n",
    "    if (predicted == actual):\n",
    "      predicted_right += 1\n",
    "    else:\n",
    "      print(\"Wrong predicted language at line\", line_number)\n",
    "      print(\"Predicted language:\", predicted)\n",
    "      print(\"Actual language:\", actual)\n",
    "      print()\n",
    "      predicted_wrong += 1\n",
    "\n",
    "print(\"Number of languages predicted right:\", predicted_right)\n",
    "print(\"Number of languages predicted wrong:\", predicted_wrong)\n",
    "print(\"Accuracy: %.2f%%\" % ((predicted_right / (predicted_right +predicted_wrong))*100) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pda9xh9YONTw"
   },
   "source": [
    "## When using log probability method, the accuracy of the predicted languages was higher. After manual testing and debugging the simplified Laplace smoothing method, I found out that the probabilty, for some cases, reaches zero in Python when the value reaches very close to zero, otherwise known as underflow. Logging the probability resolves this issue. For this assignment, I kept simplified Laplace smoothing method according to the instructions, but below is the result of the Log of the Laplace smoothing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gW2sIihozTaw",
    "outputId": "c2d31f2b-e6f4-443f-9cbd-450f01498762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong predicted language at line 44\n",
      "Predicted language: French\n",
      "Actual language: Italian\n",
      "\n",
      "Wrong predicted language at line 92\n",
      "Predicted language: French\n",
      "Actual language: English\n",
      "\n",
      "Number of languages predicted right: 298\n",
      "Number of languages predicted wrong: 2\n",
      "Accuracy: 99.33%\n"
     ]
    }
   ],
   "source": [
    "# NOTE: results of the log of the Laplace smoothing\n",
    "test_path = folder_path + \"LangId.sol.txt\"\n",
    "predicted_right = 0\n",
    "predicted_wrong = 0\n",
    "\n",
    "with open(write_file_path, 'r') as predicted_language, open(test_path, 'r') as test_file:\n",
    "  for predict_line, test_line in zip(predicted_language, test_file):\n",
    "    # Gets rid of new lines with strip()\n",
    "    predicted = predict_line.strip()\n",
    "    actual = test_line.strip()\n",
    "\n",
    "    # From the \"LangId.sol.txt\", split the line and get the second string from split\n",
    "    line_number = actual.split()[0]\n",
    "    actual = actual.split()[1]\n",
    "\n",
    "    # print(predicted)\n",
    "    # print(actual)\n",
    "    # print(\"---------------------\")\n",
    "\n",
    "    if (predicted == actual):\n",
    "      predicted_right += 1\n",
    "    else:\n",
    "      print(\"Wrong predicted language at line\", line_number)\n",
    "      print(\"Predicted language:\", predicted)\n",
    "      print(\"Actual language:\", actual)\n",
    "      print()\n",
    "      predicted_wrong += 1\n",
    "\n",
    "print(\"Number of languages predicted right:\", predicted_right)\n",
    "print(\"Number of languages predicted wrong:\", predicted_wrong)\n",
    "print(\"Accuracy: %.2f%%\" % ((predicted_right / (predicted_right +predicted_wrong))*100) )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
